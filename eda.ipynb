{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['O', 'prov', 'city', 'district', 'town', 'community', 'poi', 'road', 'roadno', 'subpoi', 'devzone', 'houseno', 'intersection', 'assist', 'cellno', 'floorno', 'distance', 'village_group'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = []\n",
    "labels = ['B', \"I\", \"E\", \"O\", 'S']\n",
    "categories = {\"O\":0}\n",
    "O_entities = []\n",
    "with open(\"data/CCKS2021中文NLP地址要素解析/train.conll\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if len(line) > 1:\n",
    "            tag = line.split(\" \")[1]\n",
    "            cha = line.split(\" \")[0]\n",
    "            if tag not in tags:\n",
    "                tags.append(tag)\n",
    "            if tag != \"O\":\n",
    "                # print(line)\n",
    "                c = tag.split('-')[1]\n",
    "                if c not in categories:\n",
    "                    categories[c] = 1\n",
    "                else:\n",
    "                    categories[c] += 1\n",
    "            else:\n",
    "                categories[tag] += 1\n",
    "                O_entities.append(cha)\n",
    "            # if \"S\" in line.split(\" \")[1]:\n",
    "            #     print(line)\n",
    "# from collections import Counter\n",
    "# Counter(O_entities)  # 'prov', 'city', 'district', 'town'\n",
    "categories.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from confs import col\n",
    "cates = ['O', 'prov', 'city', 'district', 'town', 'community', \n",
    "'poi', 'road', 'roadno', 'subpoi', 'devzone', 'houseno', \n",
    "'intersection', 'assist', 'cellno', 'floorno', 'distance', \n",
    "'village_group']\n",
    "cate_words = {}\n",
    "for cate in cates:\n",
    "    cate_words[cate] = []\n",
    "for item in col.find({}):\n",
    "    entities = item['entity']\n",
    "    tags = item['tag']\n",
    "    for i in range(len(entities)):\n",
    "        entity = entities[i]\n",
    "        cate = tags[i]\n",
    "        cate_words[cate].append(entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cate in cates:\n",
    "    with open(\"./data/entity_words/entity_{}\".format(cate), 'w') as f:\n",
    "        for ent in list(set(cate_words[cate])):\n",
    "            f.write(ent)\n",
    "            f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8856/8856 [00:00<00:00, 141411.18it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "with open(\"data/CCKS2021中文NLP地址要素解析/train.conll\") as f:\n",
    "    data = f.read()\n",
    "    lines = data.split(\"\\n\\n\")\n",
    "    for line in tqdm(lines):\n",
    "        ws = []\n",
    "        ts = []\n",
    "        line = line.strip()\n",
    "        cs = line.split('\\n')\n",
    "        for c in cs:\n",
    "            w = c.split(\" \")[0]\n",
    "            ws.append(w)\n",
    "            t = c.split(\" \")[1]\n",
    "            ts.append(t)\n",
    "        # print(ws, ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 标签与类型\n",
    "len(categories.keys()) * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags.append(\"S-district\")\n",
    "tags.append(\"S-community\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"S-district\" in tags\n",
    "# len(tags)\n",
    "tags = list(set(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle   \n",
    "with open('./data/CCKS2021中文NLP地址要素解析/tags.pkl','wb') as f:\n",
    "    pickle.dump(tags,f,0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0, 1, 0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.randint(0,1), random.randint(0,1), random.randint(0,1), random.randint(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-road',\n",
       " 'B-intersection',\n",
       " 'E-roadno',\n",
       " 'I-roadno',\n",
       " 'E-community',\n",
       " 'E-cellno',\n",
       " 'I-town',\n",
       " 'E-subpoi',\n",
       " 'I-intersection',\n",
       " 'B-assist',\n",
       " 'E-prov',\n",
       " 'B-poi',\n",
       " 'E-road',\n",
       " 'I-assist',\n",
       " 'I-prov',\n",
       " 'I-distance',\n",
       " 'E-houseno',\n",
       " 'B-distance',\n",
       " 'E-devzone',\n",
       " 'B-houseno',\n",
       " 'B-town',\n",
       " 'E-district',\n",
       " 'E-poi',\n",
       " 'I-road',\n",
       " 'B-cellno',\n",
       " 'I-houseno',\n",
       " 'I-floorno',\n",
       " 'I-district',\n",
       " 'I-subpoi',\n",
       " 'B-devzone',\n",
       " 'E-town',\n",
       " 'E-intersection',\n",
       " 'B-city',\n",
       " 'B-village_group',\n",
       " 'I-village_group',\n",
       " 'E-assist',\n",
       " 'E-floorno',\n",
       " 'E-village_group',\n",
       " 'I-city',\n",
       " 'B-district',\n",
       " 'I-cellno',\n",
       " 'B-prov',\n",
       " 'O',\n",
       " 'I-community',\n",
       " 'E-city',\n",
       " 'S-assist',\n",
       " 'S-district',\n",
       " 'B-subpoi',\n",
       " 'B-roadno',\n",
       " 'I-poi',\n",
       " 'S-community',\n",
       " 'B-community',\n",
       " 'B-floorno',\n",
       " 'S-intersection',\n",
       " 'S-poi',\n",
       " 'E-distance',\n",
       " 'I-devzone']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle   \n",
    "with open('./data/CCKS2021中文NLP地址要素解析/tags.pkl','rb') as f:\n",
    "    a = pickle.load(f)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'O' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ca971938ae39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"O\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: 'O' is not in list"
     ]
    }
   ],
   "source": [
    "tags.index(\"O\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['北京市', '密云', '区', '旅游委', '院内', '东西', '角', '停车场']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jieba\n",
    "list(jieba.cut('北京市密云区旅游委院内东西角停车场'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'上海', '上海市', '北京', '深圳'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prov_words = open('data/entity_words/entity_prov').read().split()\n",
    "# prov_words\n",
    "city_words = open('data/entity_words/entity_city').read().split()\n",
    "# city_words\n",
    "set(prov_words) & set(city_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0b9a56094d76aa47bec8a3c2b2b539bfde94a17184cf1e63694d097dfe0b6eaf"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}